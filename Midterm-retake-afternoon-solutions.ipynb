{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematics in the Real World\n",
    "### Midterm retake (afternoon) solutions\n",
    "#### Prof. Jack Poulson; May 6, 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1\n",
    "Given the dataset \n",
    "  $$ 10.5, 7, 2, -5, -20, 11, 12, 27, 30, $$\n",
    "  \n",
    "(a) **[25 pts]** Draw and label a box and whisker plot for the dataset.\n",
    "\n",
    "(b) **[10 pts]** Compute the best estimates of the dataset with respect to the two-norm and max-norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After sorting the dataset from smallest to largest, we would find\n",
    "  $$ -20, -5, 2, 7, 10.5, 11, 12, 27, 30, $$\n",
    "which has median $10.5$, Lower Quartile $2$, Upper Quartile $12$, and therefore Interquartile Range $12-2=10$. Thus, any datapoints above $\\text{UQ}+1.5*\\text{IQR}=27$ or below $\\text{LQ}-1.5*\\text{IQR}=-13$ are considered outliars (i.e., 30 and -20). The whiskers respectively end at the largest datapoint (incluseively) between 12 and 27, which is 27, and the smallest datapoint between -13 and 2, which is -5. \n",
    "\n",
    "Alternatively, we can simply ask Python to draw the box plot for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEKCAYAAAACS67iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2bc0c62dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [10.5,7,2,-5,-20,11,12,27,30]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.boxplot(x, \n",
    "            notch=False, # box instead of notch shape \n",
    "            sym='rs',    # red squares for outliers\n",
    "            vert=True)   # vertical box aligmnent\n",
    "t = plt.title('Box plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best two-norm estimate is the mean, which is\n",
    "  $$ \\frac{10.5+7+2-5-20+11+12+27+30}{9} \\approx 8.2778, $$\n",
    "while the best max-norm estimate is\n",
    "  $$ \\frac{-20+30}{2} = 5. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2\n",
    "Consider a fair random walk:\n",
    "\n",
    "(a) **[10 pts]** Write down the expected change in squared distance from zero if the walk is currently at position $k$ and takes one more step.\n",
    "\n",
    "(b) **[10 pts]** Write down the expected change in (absolute) distance from zero if the walk is currently at position $k \\neq 0$ and takes one more random step, and compute the expected change from taking a step at $k=0$.\n",
    "\n",
    "(c) **[10 pts]** Describe the behaviour (as precisely as possible) of the Variance and Mean Absolute Deviation of the random walk as the number of steps increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For part (a), the question is to compute\n",
    "  $$ E[(k+W_1)^2] - k^2, $$\n",
    "where $W_1$ is one step of a random walk. We can easily evaluate this as\n",
    "  $$ \\left(\\frac{1}{2}(k+1)^2 + \\frac{1}{2}(k-1)^2\\right) - k^2 = \\frac{1}{2}\\left( (k^2 + 2k + 1) + (k^2 - 2k + 1)\\right) - k^2 = \\frac{1}{2}\\left( 2k^2 + 2 \\right) - k^2 = 1.$$\n",
    "  \n",
    "For part (b), we seek to separately compute\n",
    "  $$ E[|k+W_1|] - |k| $$\n",
    "with $k \\neq 0$ and $k = 0$. When $k \\geq 1$, we find that, since $k-1$, $k$, and $k+1$ are all at least zero, that\n",
    "  $$ \\left(\\frac{1}{2} | k+1 | + \\frac{1}{2} | k - 1 | \\right) - |k| = \\left( \\frac{1}{2} (k+1) + \\frac{1}{2} (k-1) \\right) - k = 0, $$\n",
    "wherease, if $k \\leq 1$, we find that $k-1$, $k$, and $k+1$ are all at most zero, so that\n",
    "  $$ \\left(\\frac{1}{2} | k+1 | + \\frac{1}{2} | k - 1 | \\right) - |k| = \\left( -\\frac{1}{2} (k+1) - \\frac{1}{2} (k-1) \\right) + k = 0. $$\n",
    "Thus, as long as $k \\neq 0$, we have that the expected change in the absolute distance from zero is zero. But, if $k=0$, then we will have that $k+1$ is positive while $k-1$ is negative, and thus\n",
    "  $$ \\left(\\frac{1}{2} |k+1| + \\frac{1}{2} |k-1| \\right) - |k| = \\left( \\frac{1}{2} 1 + \\frac{1}{2} 1 \\right) - 0 = 1. $$\n",
    "  \n",
    "For part (c), part (a) allows us to conclude that every step of the random walk must increase the variance by $1$ since, regardless of where each walk is, its next step will, on average, increase the squared distance from zero by one (and the variance is nothing but the average squared distance from zero). Likewise, part (b) allows us to recognize that the Mean Absolute Deviation from step $n$ to step $n+1$ can be expressed as\n",
    "  $$ \\text{MAD}[W_{n+1}] = \\text{MAD}[W_n] + P[W_n=0]*1, $$\n",
    "since each walk that is at zero after $n$ steps will lead to an average increase of one in its absolute distance from zero after one more step. Since it is not possible for an odd number of steps to have ended at zero, we have that the probability that $n$ steps of the random walk ends at zero, $P[W_n=0]$, is zero. But, for even numbers of steps, there are $2^n$ total unique paths, and $\\binom{n}{n/2}$ of them will end at zero, and so the $P[W_n=0]=\\binom{n}{n/2} 2^{-n}$ when $n$ is even."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3\n",
    "Consider a random walk where the first step is twice as likely to be backward as forward, but subsequent steps prefer to go in the **opposite** direction as the preceding step by a factor of two. For example, if the first step was forward, the odds of the next step being backward are $2/3$. But, if the first step was forward and the second step was backward, then the odds of the third step being forward are $2/3$. If the random walk is allowed to continue for **three steps**:\n",
    "\n",
    "(a) **[5 pts]** List the possible final locations.\n",
    "\n",
    "(b) **[10 pts]** Compute the likelihoods of these locations.\n",
    "\n",
    "(c) **[5 pts]** Compute the expected location.\n",
    "\n",
    "(d) **[15 pts]** Compute the variance, standard deviation, and Mean Absolute Deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different possible random walks and their probabilities are:\n",
    "\n",
    "* FFF ends at 3 and has likelihood $(1/3)(1/3)(1/3)=1/27.$\n",
    "* FFB ends at 1 and has likelihood $(1/3)(1/3)(2/3)=2/27.$\n",
    "* FBF ends at 1 and has likelihood $(1/3)(2/3)(2/3)=4/27.$\n",
    "* FBB ends at -1 and has likelihood $(1/3)(2/3)(1/3)=2/27.$\n",
    "* BFF ends at 1 and has likelihood $(2/3)(2/3)(1/3)=4/27.$\n",
    "* BFB ends at -1 and has likelihood $(2/3)(2/3)(2/3)=8/27.$\n",
    "* BBF ends at -1 and has likelihood $(2/3)(1/3)(2/3)=4/27.$\n",
    "* BBB ends at -3 and has likelihood $(2/3)(1/3)(1/3)=2/27.$\n",
    "\n",
    "Thus, the answer to (a) is the set of locations $(-3,-1,1,3)$, and their likelihoods, for part (b), are respectively\n",
    "\n",
    "* 3 has likelihood $1/27$,\n",
    "* 1 has likelihood $2/27 + 4/27 + 4/27 = 10/27$,\n",
    "* -1 has likelihood $2/27 + 8/27 + 4/27 = 14/27$, and\n",
    "* -3 has likelihood $2/27$.\n",
    "\n",
    "For part (c), the expected final location is then\n",
    "  $$ E[W_3] = \\frac{1}{27}*(3) + \\frac{10}{27}*(1) + \\frac{14}{27}*(-1) + \\frac{2}{27}*(-3) = \\frac{-7}{27}. $$\n",
    "For part (d), the variance is then\n",
    "  $$ \\begin{eqnarray*} \\text{Var}[W_3] &=& E[(W_3-E[W_3])^2] = E[(W_3+\\frac{7}{27})^2] \\\\\n",
    "      &=& \\frac{1}{27}*(3+\\frac{7}{27})^2 + \\frac{10}{27}*(1+\\frac{7}{27})^2 + \\frac{14}{27}*(-1+\\frac{7}{27})^2 + \\frac{2}{27}*(-3+\\frac{7}{27})^2 \\\\\n",
    "      &\\approx& 1.8217, \\end{eqnarray*} $$\n",
    "and the standard deviation is the square-root of the variance, roughly $1.3497$.\n",
    "Likewise, the Mean Absolute Deviation is\n",
    "  $$ \\begin{eqnarray*}\\text{MAD}[W_3] &=& E[|W_3 - E[W_3]|] = E[|W_3 + \\frac{7}{27}|] \\\\\n",
    "     &=& \\frac{1}{27}*|3+\\frac{7}{27}| + \\frac{10}{27}*|1+\\frac{7}{27}| + \\frac{14}{27}*|-1+\\frac{7}{27}| + \\frac{2}{27}*|-3+\\frac{7}{27}| \\\\\n",
    "     &\\approx& 1.174.\\end{eqnarray*} $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
